{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Person Detecton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0WTuQxtD2SG",
        "colab_type": "code",
        "outputId": "33e5a019-b8bd-4e3d-94b6-47c40983eaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import files\n",
        "!pip install -q kaggle\n",
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 64 May 18 19:46 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKplhmT-Fg8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejCsZQH0F_SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle  datasets download -d laurentmih/aisegmentcom-matting-human-datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0ShHtcfIgVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from imutils import paths\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers. normalization import BatchNormalization\n",
        "from keras.applications import VGG16\n",
        "# !unzip  '/content/aisegmentcom-matting-human-datasets.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSAGTJ1EZJ7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory = '/content/clip_img'\n",
        "new_directory = '/content/Images' \n",
        "\n",
        "\n",
        "def copy_images():\n",
        "    for file_name in os.listdir(directory):\n",
        "        sub_dir_path = directory + '/' + file_name\n",
        "        if (os.path.isdir(sub_dir_path)):\n",
        "          for file_name1 in os.listdir(sub_dir_path):\n",
        "              sub_dir_path1 = sub_dir_path + '/' + file_name1            \n",
        "              if (os.path.isdir(sub_dir_path1)):\n",
        "                     for image_name in os.listdir(sub_dir_path1):\n",
        "                         if image_name[-4:] == '.jpg':\n",
        "                            img = cv2.imread(sub_dir_path1+'/'+image_name)                            \n",
        "                            copied_image_path = new_directory + '/' + 'person_'+image_name\n",
        "                            # print(copied_image_path)\n",
        "                            if img.size !=0:\n",
        "                                cv2.imwrite(copied_image_path, img)\n",
        "\n",
        "copy_images()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTT_9xDXgP5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for image_name in os.listdir('/content/Images'):\n",
        "                        \n",
        "#                             img = '/content/Images'+'/'+image_name\n",
        "#                             # print(img)                           \n",
        "#                             os.remove(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asvuK_ZAMaNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagePaths = list(paths.list_images('/content/Images'))\n",
        "data = []\n",
        "labels = []\n",
        " \n",
        "for imagePath in imagePaths:\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-1]\n",
        "\timage = load_img(imagePath, target_size=(224, 224),grayscale=True,color_mode='gray')#,grayscale=True,color_mode='gray'\n",
        "\timage = img_to_array(image)\n",
        "\timage = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(0)\n",
        " \n",
        "# convert the data and labels to NumPy arrays\n",
        "data = np.array(data, dtype=\"float32\") #ndarray: data ndarray with shape (3548, 224, 224, 3)\n",
        "# data=np.array(data).reshape(-1, 224, 224, 1)\n",
        "\n",
        "labels = np.array(labels)   #ndarray: labels ndarray with shape (1, 3548)\n",
        "# labels =(np.array(labels).reshape(1,-1))\n",
        "# print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRQyAFNs0PgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels =(np.array(labels).reshape(1,-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkO-v5iPOBjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "plt.imshow(data[1])\n",
        "print(len(labels))\n",
        "print(labels[2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgFJfQq8UVEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data = []\n",
        "# labels = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmwS3dJ4R4-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETyOtRnSS4sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nsamples, nx, ny = data.shape\n",
        "d2_train_dataset = data.reshape((nsamples,nx*ny))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-dD5TQ4RZEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        " \n",
        "(x_train, x_test, y_train, y_test) = train_test_split(data, labels,test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1llzWDSKTq-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(y_train))\n",
        "print(len(x_train))\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "plt.imshow(x_train[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCbjxS8r98dt",
        "colab_type": "code",
        "outputId": "5ba84edd-2615-4f3a-ed36-467e8088b9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# from keras.applications.resnet50 import ResNet50\n",
        "# CLASS_COUNT = 10\n",
        "\n",
        "# base_model = ResNet50(\n",
        "#     weights='imagenet',\n",
        "#     include_top=False, \n",
        "#     input_shape=(224, 224, 3), \n",
        "#     pooling='avg',\n",
        "# )\n",
        "# base_model.trainable = False\n",
        "# model = tf.keras.models.Sequential([\n",
        "#   base_model,\n",
        "#   Dense(CLASS_COUNT, activation='softmax'),\n",
        "# ])\n",
        "model = keras.models.Sequential()\n",
        "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(224, 224, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(2, activation = 'softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "model.fit(x_train,y_train,batch_size=32,epochs = 5, validation_split=0.3)\n",
        "# model.fit(x_train, y_train, batch_size = 50, epochs = 5, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3246 samples, validate on 1392 samples\n",
            "Epoch 1/5\n",
            "3246/3246 [==============================] - 25s 8ms/step - loss: 0.0099 - accuracy: 0.9948 - val_loss: 5.0364e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "3246/3246 [==============================] - 17s 5ms/step - loss: 2.4033e-06 - accuracy: 1.0000 - val_loss: 8.5639e-11 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "3246/3246 [==============================] - 17s 5ms/step - loss: 1.1708e-06 - accuracy: 1.0000 - val_loss: 8.5639e-11 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "3246/3246 [==============================] - 17s 5ms/step - loss: 1.0785e-06 - accuracy: 1.0000 - val_loss: 2.2266e-09 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "3246/3246 [==============================] - 17s 5ms/step - loss: 9.5188e-07 - accuracy: 1.0000 - val_loss: 7.1508e-08 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fe7d6a039e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm9gWwMdT8s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
        "y_train = np.array(y_train)\n",
        "# x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
        "x_test = tf.keras.utils.normalize(x_test,axis = 1)\n",
        "# x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
        "# x_test = tf.keras.utils.normalize(x_test,axis = 1)\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten()) \n",
        "model.add(tf.keras.layers.Dense(754,activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(600,activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(64,activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax)) \n",
        "model.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'] )\n",
        "model.fit(x_train,y_train,batch_size=32,epochs = 20, validation_split=0.3)\n",
        "predictions = model.predict(x_test)\n",
        "val_loss, val_acc = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tiDM2dWX60g",
        "colab_type": "code",
        "outputId": "3bd6cdbf-af55-445f-c58d-559464a5e055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}